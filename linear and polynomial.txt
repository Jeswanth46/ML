import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error

# Step 1: Generate sample data
np.random.seed(1)
X = 2 * np.random.rand(100, 1)
y = 4 + 3 * X + X**2 + np.random.randn(100, 1)

# Step 2: Linear Regression
lin_reg = LinearRegression()
lin_reg.fit(X, y)
y_lin_pred = lin_reg.predict(X)
mse_lin = mean_squared_error(y, y_lin_pred)

# Step 3: Polynomial Regression (degree 2)
poly = PolynomialFeatures(degree=2)
X_poly = poly.fit_transform(X)
poly_reg = LinearRegression()
poly_reg.fit(X_poly, y)
y_poly_pred = poly_reg.predict(X_poly)
mse_poly = mean_squared_error(y, y_poly_pred)

# Step 4: Plot results
plt.scatter(X, y, color='blue', label='Original Data')
plt.plot(X, y_lin_pred, color='red', label='Linear Fit')
plt.scatter(X, y_poly_pred, color='green', label='Polynomial Fit', alpha=0.5)
plt.title('Linear vs Polynomial Regression')
plt.xlabel('X')
plt.ylabel('y')
plt.legend()
plt.show()

# Step 5: Output MSE
print(f"Linear Regression MSE: {mse_lin:.4f}")
print(f"Polynomial Regression MSE: {mse_poly:.4f}")

output 

Linear Regression MSE: 5.5062
Polynomial Regression MSE: 1.0334
