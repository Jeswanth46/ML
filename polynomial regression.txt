import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score

# Step 1: Generate sample data
np.random.seed(0)
X = np.random.rand(100, 1) * 6  # Features between 0 and 6
y = 0.5 * X**3 - X**2 + X + np.random.randn(100, 1) * 5  # Cubic relationship with noise

# Step 2: Transform to polynomial features (degree 3)
poly = PolynomialFeatures(degree=3)
X_poly = poly.fit_transform(X)

# Step 3: Train linear regression on polynomial features
model = LinearRegression()
model.fit(X_poly, y)
y_pred = model.predict(X_poly)

# Step 4: Evaluate performance
mse = mean_squared_error(y, y_pred)
r2 = r2_score(y, y_pred)

# Step 5: Display results
print(f"Mean Squared Error: {mse:.2f}")
print(f"R² Score: {r2:.2f}")

# Plot
plt.scatter(X, y, color='blue', label='Actual')
x_grid = np.linspace(0, 6, 100).reshape(-1, 1)
x_grid_poly = poly.transform(x_grid)
plt.plot(x_grid, model.predict(x_grid_poly), color='red', label='Polynomial Fit')
plt.title("Polynomial Regression (degree 3)")
plt.xlabel("X")
plt.ylabel("y")
plt.legend()
plt.show()

output

Mean Squared Error: 19.17
R² Score: 0.98
